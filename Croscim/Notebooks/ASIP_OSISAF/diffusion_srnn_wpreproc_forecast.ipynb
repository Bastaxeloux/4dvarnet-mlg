{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "21v75FhSkfCq"
   },
   "source": [
    "# Score-Based Generative Modeling\n",
    "\n",
    "\n",
    "### Goals\n",
    "This is a hitchhiker's guide to score-based generative models, a family of approaches based on [estimating gradients of the data distribution](https://arxiv.org/abs/1907.05600). They have obtained high-quality samples comparable to GANs (like below, figure from [this paper](https://arxiv.org/abs/2006.09011)) without requiring adversarial training, and are considered by some to be [the new contender to GANs](https://ajolicoeur.wordpress.com/the-new-contender-to-gans-score-matching-with-langevin-sampling/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/dmidata/users/maxb/4dvarnet-starter/Notebooks/Notebook_DMI/ASIP_OSISAF\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script type=\"esms-options\">{\"shimMode\": true}</script><style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = true;\n",
       "  const py_version = '3.6.3'.replace('rc', '-rc.').replace('.dev', '-dev.');\n",
       "  const reloading = false;\n",
       "  const Bokeh = root.Bokeh;\n",
       "\n",
       "  // Set a timeout for this load but only if we are not already initializing\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || (force || !root._bokeh_is_initializing)) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks;\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "    if (js_modules == null) js_modules = [];\n",
       "    if (js_exports == null) js_exports = {};\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      // Don't load bokeh if it is still initializing\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    } else if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n",
       "      // There is nothing to load\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "    window._bokeh_on_load = on_load\n",
       "\n",
       "    function on_error(e) {\n",
       "      const src_el = e.srcElement\n",
       "      console.error(\"failed to load \" + (src_el.href || src_el.src));\n",
       "    }\n",
       "\n",
       "    const skip = [];\n",
       "    if (window.requirejs) {\n",
       "      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n",
       "      root._bokeh_is_loading = css_urls.length + 0;\n",
       "    } else {\n",
       "      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n",
       "    }\n",
       "\n",
       "    const existing_stylesheets = []\n",
       "    const links = document.getElementsByTagName('link')\n",
       "    for (let i = 0; i < links.length; i++) {\n",
       "      const link = links[i]\n",
       "      if (link.href != null) {\n",
       "        existing_stylesheets.push(link.href)\n",
       "      }\n",
       "    }\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const escaped = encodeURI(url)\n",
       "      if (existing_stylesheets.indexOf(escaped) !== -1) {\n",
       "        on_load()\n",
       "        continue;\n",
       "      }\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }    var existing_scripts = []\n",
       "    const scripts = document.getElementsByTagName('script')\n",
       "    for (let i = 0; i < scripts.length; i++) {\n",
       "      var script = scripts[i]\n",
       "      if (script.src != null) {\n",
       "        existing_scripts.push(script.src)\n",
       "      }\n",
       "    }\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const escaped = encodeURI(url)\n",
       "      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n",
       "        if (!window.requirejs) {\n",
       "          on_load();\n",
       "        }\n",
       "        continue;\n",
       "      }\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (let i = 0; i < js_modules.length; i++) {\n",
       "      const url = js_modules[i];\n",
       "      const escaped = encodeURI(url)\n",
       "      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n",
       "        if (!window.requirejs) {\n",
       "          on_load();\n",
       "        }\n",
       "        continue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (const name in js_exports) {\n",
       "      const url = js_exports[name];\n",
       "      const escaped = encodeURI(url)\n",
       "      if (skip.indexOf(escaped) >= 0 || root[name] != null) {\n",
       "        if (!window.requirejs) {\n",
       "          on_load();\n",
       "        }\n",
       "        continue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      element.textContent = `\n",
       "      import ${name} from \"${url}\"\n",
       "      window.${name} = ${name}\n",
       "      window._bokeh_on_load()\n",
       "      `\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    if (!js_urls.length && !js_modules.length) {\n",
       "      on_load()\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  const js_urls = [\"https://cdn.holoviz.org/panel/1.6.1/dist/bundled/reactiveesm/es-module-shims@^1.10.0/dist/es-module-shims.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-3.6.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.6.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.6.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.6.3.min.js\", \"https://cdn.holoviz.org/panel/1.6.1/dist/panel.min.js\"];\n",
       "  const js_modules = [];\n",
       "  const js_exports = {};\n",
       "  const css_urls = [];\n",
       "  const inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (let i = 0; i < inline_js.length; i++) {\n",
       "        try {\n",
       "          inline_js[i].call(root, root.Bokeh);\n",
       "        } catch(e) {\n",
       "          if (!reloading) {\n",
       "            throw e;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      // Cache old bokeh versions\n",
       "      if (Bokeh != undefined && !reloading) {\n",
       "        var NewBokeh = root.Bokeh;\n",
       "        if (Bokeh.versions === undefined) {\n",
       "          Bokeh.versions = new Map();\n",
       "        }\n",
       "        if (NewBokeh.version !== Bokeh.version) {\n",
       "          Bokeh.versions.set(NewBokeh.version, NewBokeh)\n",
       "        }\n",
       "        root.Bokeh = Bokeh;\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    }\n",
       "    root._bokeh_is_initializing = false\n",
       "  }\n",
       "\n",
       "  function load_or_wait() {\n",
       "    // Implement a backoff loop that tries to ensure we do not load multiple\n",
       "    // versions of Bokeh and its dependencies at the same time.\n",
       "    // In recent versions we use the root._bokeh_is_initializing flag\n",
       "    // to determine whether there is an ongoing attempt to initialize\n",
       "    // bokeh, however for backward compatibility we also try to ensure\n",
       "    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n",
       "    // before older versions are fully initialized.\n",
       "    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n",
       "      // If the timeout and bokeh was not successfully loaded we reset\n",
       "      // everything and try loading again\n",
       "      root._bokeh_timeout = Date.now() + 5000;\n",
       "      root._bokeh_is_initializing = false;\n",
       "      root._bokeh_onload_callbacks = undefined;\n",
       "      root._bokeh_is_loading = 0\n",
       "      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n",
       "      load_or_wait();\n",
       "    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n",
       "      setTimeout(load_or_wait, 100);\n",
       "    } else {\n",
       "      root._bokeh_is_initializing = true\n",
       "      root._bokeh_onload_callbacks = []\n",
       "      const bokeh_loaded = root.Bokeh != null && (root.Bokeh.version === py_version || (root.Bokeh.versions !== undefined && root.Bokeh.versions.has(py_version)));\n",
       "      if (!reloading && !bokeh_loaded) {\n",
       "        if (root.Bokeh) {\n",
       "          root.Bokeh = undefined;\n",
       "        }\n",
       "        console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "      }\n",
       "      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n",
       "        console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "        run_inline_js();\n",
       "      });\n",
       "    }\n",
       "  }\n",
       "  // Give older versions of the autoload script a head-start to ensure\n",
       "  // they initialize before we start loading newer version.\n",
       "  setTimeout(load_or_wait, 100)\n",
       "}(window));"
      ],
      "application/vnd.holoviews_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n  const py_version = '3.6.3'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  const reloading = false;\n  const Bokeh = root.Bokeh;\n\n  // Set a timeout for this load but only if we are not already initializing\n  if (typeof (root._bokeh_timeout) === \"undefined\" || (force || !root._bokeh_is_initializing)) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      // Don't load bokeh if it is still initializing\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    } else if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      // There is nothing to load\n      run_callbacks();\n      return null;\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error(e) {\n      const src_el = e.srcElement\n      console.error(\"failed to load \" + (src_el.href || src_el.src));\n    }\n\n    const skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      root._bokeh_is_loading = css_urls.length + 0;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    const existing_stylesheets = []\n    const links = document.getElementsByTagName('link')\n    for (let i = 0; i < links.length; i++) {\n      const link = links[i]\n      if (link.href != null) {\n        existing_stylesheets.push(link.href)\n      }\n    }\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const escaped = encodeURI(url)\n      if (existing_stylesheets.indexOf(escaped) !== -1) {\n        on_load()\n        continue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    var existing_scripts = []\n    const scripts = document.getElementsByTagName('script')\n    for (let i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n        existing_scripts.push(script.src)\n      }\n    }\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (let i = 0; i < js_modules.length; i++) {\n      const url = js_modules[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      const url = js_exports[name];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) >= 0 || root[name] != null) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.holoviz.org/panel/1.6.1/dist/bundled/reactiveesm/es-module-shims@^1.10.0/dist/es-module-shims.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-3.6.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.6.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.6.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.6.3.min.js\", \"https://cdn.holoviz.org/panel/1.6.1/dist/panel.min.js\"];\n  const js_modules = [];\n  const js_exports = {};\n  const css_urls = [];\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (let i = 0; i < inline_js.length; i++) {\n        try {\n          inline_js[i].call(root, root.Bokeh);\n        } catch(e) {\n          if (!reloading) {\n            throw e;\n          }\n        }\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n        var NewBokeh = root.Bokeh;\n        if (Bokeh.versions === undefined) {\n          Bokeh.versions = new Map();\n        }\n        if (NewBokeh.version !== Bokeh.version) {\n          Bokeh.versions.set(NewBokeh.version, NewBokeh)\n        }\n        root.Bokeh = Bokeh;\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      // If the timeout and bokeh was not successfully loaded we reset\n      // everything and try loading again\n      root._bokeh_timeout = Date.now() + 5000;\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      root._bokeh_is_loading = 0\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      const bokeh_loaded = root.Bokeh != null && (root.Bokeh.version === py_version || (root.Bokeh.versions !== undefined && root.Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n        if (root.Bokeh) {\n          root.Bokeh = undefined;\n        }\n        console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n        console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n        run_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "if ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n",
       "  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n",
       "}\n",
       "\n",
       "\n",
       "    function JupyterCommManager() {\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n",
       "      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        comm_manager.register_target(comm_id, function(comm) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        });\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        });\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n",
       "          var messages = comm.messages[Symbol.asyncIterator]();\n",
       "          function processIteratorResult(result) {\n",
       "            var message = result.value;\n",
       "            console.log(message)\n",
       "            var content = {data: message.data, comm_id};\n",
       "            var buffers = []\n",
       "            for (var buffer of message.buffers || []) {\n",
       "              buffers.push(new DataView(buffer))\n",
       "            }\n",
       "            var metadata = message.metadata || {};\n",
       "            var msg = {content, buffers, metadata}\n",
       "            msg_handler(msg);\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "          return messages.next().then(processIteratorResult);\n",
       "        })\n",
       "      }\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n",
       "      if (comm_id in window.PyViz.comms) {\n",
       "        return window.PyViz.comms[comm_id];\n",
       "      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n",
       "        if (msg_handler) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        }\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n",
       "        comm.open();\n",
       "        if (msg_handler) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        }\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        var comm_promise = google.colab.kernel.comms.open(comm_id)\n",
       "        comm_promise.then((comm) => {\n",
       "          window.PyViz.comms[comm_id] = comm;\n",
       "          if (msg_handler) {\n",
       "            var messages = comm.messages[Symbol.asyncIterator]();\n",
       "            function processIteratorResult(result) {\n",
       "              var message = result.value;\n",
       "              var content = {data: message.data};\n",
       "              var metadata = message.metadata || {comm_id};\n",
       "              var msg = {content, metadata}\n",
       "              msg_handler(msg);\n",
       "              return messages.next().then(processIteratorResult);\n",
       "            }\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "        })\n",
       "        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n",
       "          return comm_promise.then((comm) => {\n",
       "            comm.send(data, metadata, buffers, disposeOnDone);\n",
       "          });\n",
       "        };\n",
       "        var comm = {\n",
       "          send: sendClosure\n",
       "        };\n",
       "      }\n",
       "      window.PyViz.comms[comm_id] = comm;\n",
       "      return comm;\n",
       "    }\n",
       "    window.PyViz.comm_manager = new JupyterCommManager();\n",
       "    \n",
       "\n",
       "\n",
       "var JS_MIME_TYPE = 'application/javascript';\n",
       "var HTML_MIME_TYPE = 'text/html';\n",
       "var EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\n",
       "var CLASS_NAME = 'output';\n",
       "\n",
       "/**\n",
       " * Render data to the DOM node\n",
       " */\n",
       "function render(props, node) {\n",
       "  var div = document.createElement(\"div\");\n",
       "  var script = document.createElement(\"script\");\n",
       "  node.appendChild(div);\n",
       "  node.appendChild(script);\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when a new output is added\n",
       " */\n",
       "function handle_add_output(event, handle) {\n",
       "  var output_area = handle.output_area;\n",
       "  var output = handle.output;\n",
       "  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "    return\n",
       "  }\n",
       "  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "  if (id !== undefined) {\n",
       "    var nchildren = toinsert.length;\n",
       "    var html_node = toinsert[nchildren-1].children[0];\n",
       "    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var scripts = [];\n",
       "    var nodelist = html_node.querySelectorAll(\"script\");\n",
       "    for (var i in nodelist) {\n",
       "      if (nodelist.hasOwnProperty(i)) {\n",
       "        scripts.push(nodelist[i])\n",
       "      }\n",
       "    }\n",
       "\n",
       "    scripts.forEach( function (oldScript) {\n",
       "      var newScript = document.createElement(\"script\");\n",
       "      var attrs = [];\n",
       "      var nodemap = oldScript.attributes;\n",
       "      for (var j in nodemap) {\n",
       "        if (nodemap.hasOwnProperty(j)) {\n",
       "          attrs.push(nodemap[j])\n",
       "        }\n",
       "      }\n",
       "      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n",
       "      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n",
       "      oldScript.parentNode.replaceChild(newScript, oldScript);\n",
       "    });\n",
       "    if (JS_MIME_TYPE in output.data) {\n",
       "      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n",
       "    }\n",
       "    output_area._hv_plot_id = id;\n",
       "    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n",
       "      window.PyViz.plot_index[id] = Bokeh.index[id];\n",
       "    } else {\n",
       "      window.PyViz.plot_index[id] = null;\n",
       "    }\n",
       "  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "    var bk_div = document.createElement(\"div\");\n",
       "    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var script_attrs = bk_div.children[0].attributes;\n",
       "    for (var i = 0; i < script_attrs.length; i++) {\n",
       "      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "    }\n",
       "    // store reference to server id on output_area\n",
       "    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when an output is cleared or removed\n",
       " */\n",
       "function handle_clear_output(event, handle) {\n",
       "  var id = handle.cell.output_area._hv_plot_id;\n",
       "  var server_id = handle.cell.output_area._bokeh_server_id;\n",
       "  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n",
       "  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n",
       "  if (server_id !== null) {\n",
       "    comm.send({event_type: 'server_delete', 'id': server_id});\n",
       "    return;\n",
       "  } else if (comm !== null) {\n",
       "    comm.send({event_type: 'delete', 'id': id});\n",
       "  }\n",
       "  delete PyViz.plot_index[id];\n",
       "  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n",
       "    var doc = window.Bokeh.index[id].model.document\n",
       "    doc.clear();\n",
       "    const i = window.Bokeh.documents.indexOf(doc);\n",
       "    if (i > -1) {\n",
       "      window.Bokeh.documents.splice(i, 1);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle kernel restart event\n",
       " */\n",
       "function handle_kernel_cleanup(event, handle) {\n",
       "  delete PyViz.comms[\"hv-extension-comm\"];\n",
       "  window.PyViz.plot_index = {}\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle update_display_data messages\n",
       " */\n",
       "function handle_update_output(event, handle) {\n",
       "  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n",
       "  handle_add_output(event, handle)\n",
       "}\n",
       "\n",
       "function register_renderer(events, OutputArea) {\n",
       "  function append_mime(data, metadata, element) {\n",
       "    // create a DOM node to render to\n",
       "    var toinsert = this.create_output_subarea(\n",
       "    metadata,\n",
       "    CLASS_NAME,\n",
       "    EXEC_MIME_TYPE\n",
       "    );\n",
       "    this.keyboard_manager.register_events(toinsert);\n",
       "    // Render to node\n",
       "    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "    render(props, toinsert[0]);\n",
       "    element.append(toinsert);\n",
       "    return toinsert\n",
       "  }\n",
       "\n",
       "  events.on('output_added.OutputArea', handle_add_output);\n",
       "  events.on('output_updated.OutputArea', handle_update_output);\n",
       "  events.on('clear_output.CodeCell', handle_clear_output);\n",
       "  events.on('delete.Cell', handle_clear_output);\n",
       "  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n",
       "\n",
       "  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "    safe: true,\n",
       "    index: 0\n",
       "  });\n",
       "}\n",
       "\n",
       "if (window.Jupyter !== undefined) {\n",
       "  try {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  } catch(err) {\n",
       "  }\n",
       "}\n"
      ],
      "application/vnd.holoviews_load.v0+json": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        })\n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='p1002'>\n",
       "  <div id=\"fc4a932f-2a71-43be-abc4-c659657999ab\" data-root-id=\"p1002\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"ba030f18-6214-40f4-af94-f4bb99e1401a\":{\"version\":\"3.6.3\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"p1002\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"p1003\",\"attributes\":{\"plot_id\":\"p1002\",\"comm_id\":\"972ed502c34b4051a229b65d7c317d12\",\"client_comm_id\":\"45275ac163c0421ea789f3114beb5ea0\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_rendered\",\"kind\":\"Any\",\"default\":false},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"ReactiveESM1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"JSComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"ReactComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"AnyWidgetComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"request_value1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"_synced\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_request_sync\",\"kind\":\"Any\",\"default\":0}]}]}};\n",
       "  var render_items = [{\"docid\":\"ba030f18-6214-40f4-af94-f4bb99e1401a\",\"roots\":{\"p1002\":\"fc4a932f-2a71-43be-abc4-c659657999ab\"},\"root_ids\":[\"p1002\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  async function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    await Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && id_el.children[0].hasAttribute('data-root-id')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t  for (const child of root_el.children) {\n",
       "            // Ensure JupyterLab does not capture keyboard shortcuts\n",
       "            // see: https://jupyterlab.readthedocs.io/en/4.1.x/extension/notebook.html#keyboard-interaction-model\n",
       "\t    child.setAttribute('data-lm-suppress-shortcuts', 'true')\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "p1002"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "print(os.getcwd())\n",
    "sys.path.append('../../..')\n",
    "from contrib.DMI.ASIP_OSISAF.data_simple import *\n",
    "from src.utils import *\n",
    "from src.models import *\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import itertools\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoSeries\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "datamodule = BaseDataModule(asip_paths=\"/dmidata/users/maxb/ASIP_OSISAF_dataset/PREPROC/asip_database.nc\",\n",
    "                            split_train=slice(0,900),\n",
    "                            split_val=slice(900,950),\n",
    "                            split_test=slice(950,1000))\n",
    "                            \n",
    "datamodule.setup()\n",
    "\n",
    "data_loader = datamodule.train_dataloader()\n",
    "val_dataloader = datamodule.val_dataloader()\n",
    "test_dataloader = datamodule.test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 8, 240, 240])\n"
     ]
    }
   ],
   "source": [
    "k=10\n",
    "my_sample = next(itertools.islice(data_loader, k, None))\n",
    "print(my_sample[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "form",
    "id": "YyQtV7155Nht"
   },
   "outputs": [],
   "source": [
    "#@title Defining a time-dependent score-based model (double click to expand or collapse)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class GaussianFourierProjection(nn.Module):\n",
    "  \"\"\"Gaussian random features for encoding time steps.\"\"\"  \n",
    "  def __init__(self, embed_dim, scale=30.):\n",
    "    super().__init__()\n",
    "    # Randomly sample weights during initialization. These weights are fixed \n",
    "    # during optimization and are not trainable.\n",
    "    self.W = nn.Parameter(torch.randn(embed_dim // 2) * scale, requires_grad=False)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x_proj = x[:, None] * self.W[None, :] * 2 * np.pi\n",
    "    ret = torch.cat([torch.sin(x_proj), torch.cos(x_proj)], dim=-1)\n",
    "    return ret\n",
    "\n",
    "class Dense(nn.Module):\n",
    "    \"\"\"A fully connected layer that reshapes outputs to feature maps.\n",
    "  Allow time repr to input additively from the side of a convolution layer.\n",
    "  \"\"\"\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(input_dim, output_dim)\n",
    "    def forward(self, x):\n",
    "        return self.dense(x)[..., None, None,None] # add one dimension here with one more None\n",
    "\n",
    "class ScoreNet(nn.Module):\n",
    "    \"\"\"A time-dependent score-based model built upon U-Net architecture.\"\"\"\n",
    "\n",
    "    def __init__(self, marginal_prob_std, channels=[64, 128, 256, 512], \n",
    "                 embed_dim=256, \n",
    "                 text_dim=1, nAttr=40):\n",
    "        \"\"\"Initialize a time-dependent score-based network.\n",
    "\n",
    "        Args:\n",
    "          marginal_prob_std: A function that takes time t and gives the standard\n",
    "            deviation of the perturbation kernel p_{0t}(x(t) | x(0)).\n",
    "          channels: The number of channels for feature maps of each resolution.\n",
    "          embed_dim: The dimensionality of Gaussian random feature embeddings.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Gaussian random feature embedding layer for time\n",
    "        self.embed = nn.Sequential(GaussianFourierProjection(embed_dim=embed_dim),\n",
    "                                   nn.Linear(embed_dim, embed_dim))\n",
    "        # Encoding layers where the resolution decreases\n",
    "        #self.conv1 = nn.Conv3d(3, channels[0], 3, stride=1,padding=1, bias=False)#change 25a: making 2 instead of 9 as Mahima code #change 49g: using corresponding with time-windows for 3D generative #change 50d 2*time_window by 2 here\n",
    "        self.conv1 = nn.Conv3d(2, channels[0], 3, stride=1,padding=1, bias=False)#change 25a: making 2 instead of 9 as Mahima code #change 49g: using corresponding with time-windows for 3D generative #change 50d 2*time_window by 2 here\n",
    "        self.dense1 = Dense(embed_dim, channels[0])\n",
    "        self.gnorm1 = nn.GroupNorm(4, num_channels=channels[0])\n",
    "        self.conv2 = nn.Conv3d(channels[0], channels[1], 3, stride=2,padding=1, bias=False, )\n",
    "        self.dense2 = Dense(embed_dim, channels[1])\n",
    "        self.gnorm2 = nn.GroupNorm(32, num_channels=channels[1])\n",
    "        self.conv3 = nn.Conv3d(channels[1], channels[2], 3, stride=2,padding=1, bias=False, )\n",
    "        self.dense3 = Dense(embed_dim, channels[2])\n",
    "        self.gnorm3 = nn.GroupNorm(32, num_channels=channels[2])\n",
    "        # self.attn3 = SpatialTransformer(channels[2], text_dim)\n",
    "        self.conv4 = nn.Conv3d(channels[2], channels[3], 3, stride=2,padding=1, bias=False, )\n",
    "        self.dense4 = Dense(embed_dim, channels[3])\n",
    "        self.gnorm4 = nn.GroupNorm(32, num_channels=channels[3])\n",
    "        # self.attn4 = SpatialTransformer(channels[3], text_dim)\n",
    "\n",
    "        # Decoding layers where the resolution increases\n",
    "        self.tconv4 = nn.ConvTranspose3d(channels[3], channels[2], 3, stride=2, bias=False, padding=1, output_padding=1) #change 25b: add padding here\n",
    "        self.dense5 = Dense(embed_dim, channels[2])\n",
    "        self.tgnorm4 = nn.GroupNorm(32, num_channels=channels[2])\n",
    "        # self.attn5 = SpatialTransformer(channels[2], text_dim)\n",
    "        self.tconv3 = nn.ConvTranspose3d(channels[2], channels[1], 3, stride=2, bias=False,\n",
    "                                          padding=1, output_padding=1)  # , output_padding=1)     #  + channels[2]\n",
    "        self.dense6 = Dense(embed_dim, channels[1])\n",
    "        self.tgnorm3 = nn.GroupNorm(32, num_channels=channels[1])\n",
    "        self.tconv2 = nn.ConvTranspose3d(channels[1], channels[0], 3, stride=2, bias=False,\n",
    "                                        padding=1, output_padding=1)  # , output_padding=1)     #  + channels[1]\n",
    "        self.dense7 = Dense(embed_dim, channels[0])\n",
    "        self.tgnorm2 = nn.GroupNorm(32, num_channels=channels[0])\n",
    "        self.tconv1 = nn.ConvTranspose3d(channels[0], 1, 3, stride=1,padding=1)  # + channels[0] #change 49o: must be time window in the output here #change 50e: time_window by 1 here\n",
    "\n",
    "        # The swish activation function\n",
    "        self.act = nn.SiLU()  # lambda x: x * torch.sigmoid(x)\n",
    "        self.marginal_prob_std = marginal_prob_std\n",
    "        self.cond_embed = nn.Embedding(nAttr + 1, text_dim, padding_idx=nAttr)  # +1 for the padding index\n",
    "\n",
    "    def forward(self, x, t, y=None, mask=None):\n",
    "        \n",
    "        # Obtain the Gaussian random feature embedding for t\n",
    "        embed = self.act(self.embed(t))\n",
    "        # print('y', y.shape)\n",
    "\n",
    "        #x= torch.cat((x, y, mask), 1)\n",
    "        x= torch.cat((x, y), 1)\n",
    "        # print('x after concating y', x.shape)\n",
    "\n",
    "        # print('conv1 before add dense', self.conv1(x).shape)\n",
    "        # print('dense1', self.dense1(embed).shape)\n",
    "        h1 = self.conv1(x) + self.dense1(embed)\n",
    "        # print('conv1 after add dense', h1.shape)\n",
    "\n",
    "        h1 = self.act(self.gnorm1(h1))\n",
    "        # print('conv2 before add dense', self.conv2(h1).shape)\n",
    "        # print('dense2', self.dense2(embed).shape)\n",
    "        h2 = self.conv2(h1) + self.dense2(embed)\n",
    "        # print('conv2', h2.shape)\n",
    "        h2 = self.act(self.gnorm2(h2))\n",
    "        h3 = self.conv3(h2) + self.dense3(embed)\n",
    "        # print('h3', h3.shape)\n",
    "        h3 = self.act(self.gnorm3(h3))\n",
    "        h4 = self.conv4(h3) + self.dense4(embed)\n",
    "        h4 = self.act(self.gnorm4(h4))\n",
    "        # print('h4', h4.shape)\n",
    "        \n",
    "        # Decoding path\n",
    "        h = self.tconv4(h4) + self.dense5(embed)\n",
    "        # print('tconv4', h.shape)\n",
    "        ## Skip connection from the encoding path\n",
    "        h = self.act(self.tgnorm4(h))\n",
    "        h = self.tconv3(h + h3) + self.dense6(embed)\n",
    "        # print('tconv3', h.shape)\n",
    "        h = self.act(self.tgnorm3(h))\n",
    "        h = self.tconv2(h + h2) + self.dense7(embed)\n",
    "        # print('tconv2', h.shape)\n",
    "        h = self.act(self.tgnorm2(h))\n",
    "        h = self.tconv1(h + h1)\n",
    "        # print('tconv1', h.shape)\n",
    "        \n",
    "        # Normalize output\n",
    "        h = h / self.marginal_prob_std(t)[:,None, None, None, None] #add one dimension for 3D setting here\n",
    "        # print('final output', h.shape)\n",
    "        # print(\"self.marginal_prob_std(t) 3D setting:\", self.marginal_prob_std(t))\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PpJSwfyY6mJz"
   },
   "source": [
    "## Training with Weighted Sum of Denoising Score Matching Objectives\n",
    "\n",
    "Now let's get our hands dirty on training. First of all, we need to specify an SDE that perturbs the data distribution $p_0$ to a prior distribution $p_T$. We choose the following SDE\n",
    "\\begin{align*}\n",
    "d \\mathbf{x} = \\sigma^t d\\mathbf{w}, \\quad t\\in[0,1]\n",
    "\\end{align*}\n",
    "In this case,\n",
    "\\begin{align*}\n",
    "p_{0t}(\\mathbf{x}(t) \\mid \\mathbf{x}(0)) = \\mathcal{N}\\bigg(\\mathbf{x}(t); \\mathbf{x}(0), \\frac{1}{2\\log \\sigma}(\\sigma^{2t} - 1) \\mathbf{I}\\bigg)\n",
    "\\end{align*}\n",
    "and we can choose the weighting function $\\lambda(t) = \\frac{1}{2 \\log \\sigma}(\\sigma^{2t} - 1)$.\n",
    "\n",
    "When $\\sigma$ is large, the prior distribution, $p_{t=1}$ is\n",
    "\\begin{align*}\n",
    "\\int p_0(\\mathbf{y})\\mathcal{N}\\bigg(\\mathbf{x}; \\mathbf{y}, \\frac{1}{2 \\log \\sigma}(\\sigma^2 - 1)\\mathbf{I}\\bigg) d \\mathbf{y} \\approx \\mathbf{N}\\bigg(\\mathbf{x}; \\mathbf{0}, \\frac{1}{2 \\log \\sigma}(\\sigma^2 - 1)\\mathbf{I}\\bigg),\n",
    "\\end{align*}\n",
    "which is approximately independent of the data distribution and is easy to sample from.\n",
    "\n",
    "Intuitively, this SDE captures a continuum of Gaussian perturbations with variance function $\\frac{1}{2 \\log \\sigma}(\\sigma^{2t} - 1)$. This continuum of perturbations allows us to gradually transfer samples from a data distribution $p_0$ to a simple Gaussian distribution $p_1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellView": "form",
    "id": "LZC7wrOvxLdL"
   },
   "outputs": [],
   "source": [
    "#@title Set up the SDE\n",
    "\n",
    "import functools\n",
    "device = 'cuda'\n",
    "#device = 'cpu' #@param ['cuda', 'cpu'] {'type':'string'}\n",
    "\n",
    "def marginal_prob_std(t, sigma):\n",
    "  \"\"\"Compute the mean and standard deviation of $p_{0t}(x(t) | x(0))$.\n",
    "\n",
    "  Args:\n",
    "    t: A vector of time steps.\n",
    "    sigma: The sigma in our SDE.\n",
    "\n",
    "  Returns:\n",
    "    The standard deviation.\n",
    "  \"\"\"\n",
    "  t = torch.tensor(t, device=device)\n",
    "  return torch.sqrt((sigma**(2 * t) - 1.) / 2. / np.log(sigma))\n",
    "\n",
    "def diffusion_coeff(t, sigma):\n",
    "  \"\"\"Compute the diffusion coefficient of our SDE.\n",
    "\n",
    "  Args:\n",
    "    t: A vector of time steps.\n",
    "    sigma: The sigma in our SDE.\n",
    "\n",
    "  Returns:\n",
    "    The vector of diffusion coefficients.\n",
    "  \"\"\"\n",
    "  return torch.tensor(sigma**t, device=device)\n",
    "\n",
    "sigma =  25.0#@param {'type':'number'}\n",
    "#sigma = 5.0\n",
    "marginal_prob_std_fn = functools.partial(marginal_prob_std, sigma=sigma)\n",
    "diffusion_coeff_fn = functools.partial(diffusion_coeff, sigma=sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cellView": "form",
    "id": "zOsoqPdXHuL5"
   },
   "outputs": [],
   "source": [
    "#@title Define the loss function (double click to expand or collapse)\n",
    "\n",
    "def loss_fn(model, x, y, marginal_prob_std, eps=1e-5):\n",
    "  \"\"\"The loss function for training score-based generative models.\n",
    "\n",
    "  Args:\n",
    "    model: A PyTorch model instance that represents a\n",
    "      time-dependent score-based model.\n",
    "    x: A mini-batch of training data.\n",
    "    marginal_prob_std: A function that gives the standard deviation of\n",
    "      the perturbation kernel.\n",
    "    eps: A tolerance value for numerical stability.\n",
    "  \"\"\"\n",
    "  random_t = torch.rand(x.shape[0], device=x.device) * (1. - eps) + eps\n",
    "  z = torch.randn_like(x).to(device)\n",
    "  std = marginal_prob_std(random_t)\n",
    "  perturbed_x = x + z * std[:, None, None, None]\n",
    "  score = model(perturbed_x, y, random_t)\n",
    "  loss = torch.mean(torch.sum((score * std[:, None, None, None] + z)**2, dim=(1,2,3)))\n",
    "  return loss\n",
    "\n",
    "def masked_loss_fn(model, x,  y, marginal_prob_std, eps=1e-5):\n",
    "  \"\"\"The loss function for training score-based generative models.\n",
    "\n",
    "  Args:\n",
    "    model: A PyTorch model instance that represents a\n",
    "      time-dependent score-based model.\n",
    "    x: A mini-batch of training data.\n",
    "    marginal_prob_std: A function that gives the standard deviation of\n",
    "      the perturbation kernel.\n",
    "    eps: A tolerance value for numerical stability.\n",
    "  \"\"\"\n",
    "\n",
    "  mask = ~torch.isnan(x)  # mask is True where x is not NaN\n",
    "  mask_obs = ~torch.isnan(y)\n",
    "  x = torch.nan_to_num(x)  \n",
    "  y = torch.nan_to_num(y)  \n",
    "  \n",
    "  random_t = torch.rand(x.shape[0], device=x.device) * (1. - eps) + eps\n",
    "  z = torch.randn_like(x)\n",
    "  std = marginal_prob_std(random_t)\n",
    "  perturbed_x = x + z * std[:, None, None, None, None] # add one dimension here\n",
    "  score = model(perturbed_x, t=random_t, y=y)#, mask=mask_obs)\n",
    "  \n",
    "  # Step 2: Compute the loss as usual\n",
    "  loss = (score * std[:, None, None, None, None] + z) ** 2 # add one dimension here\n",
    "  \n",
    "  # Step 3: Apply the mask\n",
    "  loss = loss * mask.float()  # Only consider non-NaN pixels\n",
    "  \n",
    "  # Step 4: Compute the mean loss over valid pixels\n",
    "  loss = torch.sum(loss, dim=(1, 2, 3))  # Sum over spatial dimensions\n",
    "  valid_pixel_count = torch.sum(mask, dim=(1, 2, 3))  # Count valid pixels\n",
    "  loss = loss / valid_pixel_count  # Normalize loss by valid pixel count\n",
    "  loss = torch.mean(loss)  # Average over the batch\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tldaUHUtHuej"
   },
   "source": [
    "## Sampling with Numerical SDE Solvers\n",
    "Recall that for any SDE of the form\n",
    "\\begin{align*}\n",
    "d \\mathbf{x} = \\mathbf{f}(\\mathbf{x}, t) dt + g(t) d\\mathbf{w},\n",
    "\\end{align*}\n",
    "the reverse-time SDE is given by\n",
    "\\begin{align*}\n",
    "d \\mathbf{x} = [\\mathbf{f}(\\mathbf{x}, t) - g(t)^2 \\nabla_\\mathbf{x} \\log p_t(\\mathbf{x})] dt + g(t) d \\bar{\\mathbf{w}}.\n",
    "\\end{align*}\n",
    "Since we have chosen the forward SDE to be\n",
    "\\begin{align*}\n",
    "d \\mathbf{x} = \\sigma^t d\\mathbf{w}, \\quad t\\in[0,1]\n",
    "\\end{align*}\n",
    "The reverse-time SDE is given by\n",
    "\\begin{align*}\n",
    "d\\mathbf{x} = -\\sigma^{2t} \\nabla_\\mathbf{x} \\log p_t(\\mathbf{x}) dt + \\sigma^t d \\bar{\\mathbf{w}}.\n",
    "\\end{align*}\n",
    "To sample from our time-dependent score-based model $s_\\theta(\\mathbf{x}, t)$, we first draw a sample from the prior distribution $p_1 \\approx \\mathbf{N}\\bigg(\\mathbf{x}; \\mathbf{0}, \\frac{1}{2}(\\sigma^{2} - 1) \\mathbf{I}\\bigg)$, and then solve the reverse-time SDE with numerical methods.\n",
    "\n",
    "In particular, using our time-dependent score-based model, the reverse-time SDE can be approximated by\n",
    "\\begin{align*}\n",
    "d\\mathbf{x} = -\\sigma^{2t} s_\\theta(\\mathbf{x}, t) dt + \\sigma^t d \\bar{\\mathbf{w}}\n",
    "\\end{align*}\n",
    "\n",
    "Next, one can use numerical methods to solve for the reverse-time SDE, such as the [Euler-Maruyama](https://en.wikipedia.org/wiki/Euler%E2%80%93Maruyama_method) approach. It is based on a simple discretization to the SDE, replacing $dt$ with $\\Delta t$ and $d \\mathbf{w}$ with $\\mathbf{z} \\sim \\mathcal{N}(\\mathbf{0}, g^2(t) \\Delta t \\mathbf{I})$. When applied to our reverse-time SDE, we can obtain the following iteration rule\n",
    "\\begin{align}\n",
    "\\mathbf{x}_{t-\\Delta t} = \\mathbf{x}_t + \\sigma^{2t} s_\\theta(\\mathbf{x}_t, t)\\Delta t + \\sigma^t\\sqrt{\\Delta t} \\mathbf{z}_t,\n",
    "\\end{align}\n",
    "where $\\mathbf{z}_t \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cellView": "form",
    "id": "6FxBTOSSH2QR"
   },
   "outputs": [],
   "source": [
    "#@title Define the Euler-Maruyama sampler (double click to expand or collapse)\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "## The number of sampling steps.\n",
    "num_steps =  500#@param {'type':'integer'}\n",
    "#num_steps = 100\n",
    "\n",
    "def Euler_Maruyama_sampler(score_model,\n",
    "                           marginal_prob_std,\n",
    "                           diffusion_coeff,\n",
    "                           y,\n",
    "                           batch_size=64,\n",
    "                           num_steps=num_steps,\n",
    "                           device='cuda',\n",
    "                           eps=1e-3):\n",
    "  \"\"\"Generate samples from score-based models with the Euler-Maruyama solver.\n",
    "\n",
    "  Args:\n",
    "    score_model: A PyTorch model that represents the time-dependent score-based model.\n",
    "    marginal_prob_std: A function that gives the standard deviation of\n",
    "      the perturbation kernel.\n",
    "    diffusion_coeff: A function that gives the diffusion coefficient of the SDE.\n",
    "    batch_size: The number of samplers to generate by calling this function once.\n",
    "    num_steps: The number of sampling steps.\n",
    "      Equivalent to the number of discretized time steps.\n",
    "    device: 'cuda' for running on GPUs, and 'cpu' for running on CPUs.\n",
    "    eps: The smallest time step for numerical stability.\n",
    "\n",
    "  Returns:\n",
    "    Samples.\n",
    "  \"\"\"\n",
    "  t = torch.ones(batch_size, device=device)\n",
    "  init_x = torch.randn(y.size(), device=device) \\\n",
    "    * marginal_prob_std(t)[:, None,None,None,None]\n",
    "  time_steps = torch.linspace(1., eps, num_steps, device=device)\n",
    "  tqdm_time_steps = tqdm(time_steps)    \n",
    "  step_size = time_steps[0] - time_steps[1]\n",
    "  x = init_x\n",
    "  mask_obs = ~torch.isnan(y)\n",
    "  y = y.nan_to_num()\n",
    "  with torch.no_grad():\n",
    "    for time_step in tqdm_time_steps:\n",
    "      batch_time_step = torch.ones(batch_size, device=device) * time_step\n",
    "      g = diffusion_coeff(batch_time_step)\n",
    "      mean_x = x + (g**2)[:, None,None,None,None] * score_model(x, batch_time_step, y, mask_obs) * step_size\n",
    "      x = mean_x + torch.sqrt(step_size) * g[:, None,None,None,None] * torch.randn_like(x)\n",
    "  # Do not include any noise in the last sampling step.\n",
    "  return mean_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DC6QVkUQvFyB"
   },
   "source": [
    "## Sampling with Predictor-Corrector Methods\n",
    "\n",
    "Aside from generic numerical SDE solvers, we can leverage special properties of our reverse-time SDE for better solutions. Since we have an estimate of the score of $p_t(\\mathbf{x}(t))$ via the score-based model, i.e., $s_\\theta(\\mathbf{x}, t) \\approx \\nabla_{\\mathbf{x}(t)} \\log p_t(\\mathbf{x}(t))$, we can leverage score-based MCMC approaches, such as Langevin MCMC, to correct the solution obtained by numerical SDE solvers.\n",
    "\n",
    "Score-based MCMC approaches can produce samples from a distribution $p(\\mathbf{x})$ once its score $\\nabla_\\mathbf{x} \\log p(\\mathbf{x})$ is known. For example, Langevin MCMC operates by running the following iteration rule for $i=1,2,\\cdots, N$:\n",
    "\\begin{align*}\n",
    "\\mathbf{x}_{i+1} = \\mathbf{x}_{i} + \\epsilon \\nabla_\\mathbf{x} \\log p(\\mathbf{x}_i) + \\sqrt{2\\epsilon} \\mathbf{z}_i,\n",
    "\\end{align*}\n",
    "where $\\mathbf{z}_i \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})$, $\\epsilon > 0$ is the step size, and $\\mathbf{x}_1$ is initialized from any prior distribution $\\pi(\\mathbf{x}_1)$. When $N\\to\\infty$ and $\\epsilon \\to 0$, the final value $\\mathbf{x}_{N+1}$ becomes a sample from $p(\\mathbf{x})$ under some regularity conditions. Therefore, given $s_\\theta(\\mathbf{x}, t) \\approx \\nabla_\\mathbf{x} \\log p_t(\\mathbf{x})$, we can get an approximate sample from $p_t(\\mathbf{x})$ by running several steps of Langevin MCMC, replacing $\\nabla_\\mathbf{x} \\log p_t(\\mathbf{x})$ with $s_\\theta(\\mathbf{x}, t)$ in the iteration rule.\n",
    "\n",
    "Predictor-Corrector samplers combine both numerical solvers for the reverse-time SDE and the Langevin MCMC approach. In particular, we first apply one step of numerical SDE solver to obtain $\\mathbf{x}_{t-\\Delta t}$ from $\\mathbf{x}_t$, which is called the \"predictor\" step. Next, we apply several steps of Langevin MCMC to refine $\\mathbf{x}_t$, such that $\\mathbf{x}_t$ becomes a more accurate sample from $p_{t-\\Delta t}(\\mathbf{x})$. This is the \"corrector\" step as the MCMC helps reduce the error of the numerical SDE solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cellView": "form",
    "id": "qW1HaPZb9gDM"
   },
   "outputs": [],
   "source": [
    "#@title Define the Predictor-Corrector sampler (double click to expand or collapse)\n",
    "\n",
    "signal_to_noise_ratio = 0.16 #@param {'type':'number'}\n",
    "\n",
    "## The number of sampling steps.\n",
    "num_steps =  500#@param {'type':'integer'}\n",
    "def pc_sampler(score_model,\n",
    "               marginal_prob_std,\n",
    "               diffusion_coeff,\n",
    "               batch_size=64,\n",
    "               num_steps=num_steps,\n",
    "               snr=signal_to_noise_ratio,\n",
    "               device='cuda',\n",
    "               eps=1e-3,\n",
    "               cond=False):\n",
    "  \"\"\"Generate samples from score-based models with Predictor-Corrector method.\n",
    "\n",
    "  Args:\n",
    "    score_model: A PyTorch model that represents the time-dependent score-based model.\n",
    "    marginal_prob_std: A function that gives the standard deviation\n",
    "      of the perturbation kernel.\n",
    "    diffusion_coeff: A function that gives the diffusion coefficient\n",
    "      of the SDE.\n",
    "    batch_size: The number of samplers to generate by calling this function once.\n",
    "    num_steps: The number of sampling steps.\n",
    "      Equivalent to the number of discretized time steps.\n",
    "    device: 'cuda' for running on GPUs, and 'cpu' for running on CPUs.\n",
    "    eps: The smallest time step for numerical stability.\n",
    "\n",
    "  Returns:\n",
    "    Samples.\n",
    "  \"\"\"\n",
    "  t = torch.ones(batch_size, device=device)\n",
    "  init_x = torch.randn(batch_size, 15, 240, 240, device=device) * marginal_prob_std(t)[:, None, None, None]\n",
    "  time_steps = np.linspace(1., eps, num_steps)\n",
    "  tqdm_time_steps = tqdm(time_steps)  \n",
    "  step_size = time_steps[0] - time_steps[1]\n",
    "  x = init_x\n",
    "  with torch.no_grad():\n",
    "    for time_step in tqdm_time_steps:\n",
    "      batch_time_step = torch.ones(batch_size, device=device) * time_step\n",
    "      # Corrector step (Langevin MCMC)\n",
    "      grad = score_model(x, batch_time_step)   \n",
    "      grad_norm = torch.norm(grad.reshape(grad.shape[0], -1), dim=-1).mean()\n",
    "      noise_norm = np.sqrt(np.prod(x.shape[1:]))\n",
    "      langevin_step_size = 2 * (snr * noise_norm / grad_norm)**2\n",
    "      x = x + langevin_step_size * grad + torch.sqrt(2 * langevin_step_size) * torch.randn_like(x)\n",
    "\n",
    "      # Predictor step (Euler-Maruyama)\n",
    "      g = diffusion_coeff(batch_time_step)\n",
    "      if cond:\n",
    "        x_mean = x + (g**2)[:, None, None, None] * (score_model(x, batch_time_step) + grado) * step_size\n",
    "      else:\n",
    "        x_mean = x + (g**2)[:, None, None, None] * (score_model(x, batch_time_step)) * step_size  \n",
    "      x = x_mean + torch.sqrt(g**2 * step_size)[:, None, None, None] * torch.randn_like(x)\n",
    "\n",
    "    # The last step does not include any noise\n",
    "    return x_mean\n",
    "\n",
    "test = False\n",
    "if test:\n",
    "  # test\n",
    "  ckpt = torch.load('ckpt/ckpt.pth', map_location=device)\n",
    "  score_model.load_state_dict(ckpt)\n",
    "  x_estim = pc_sampler(score_model,\n",
    "                           marginal_prob_std_fn,\n",
    "                           diffusion_coeff_fn,\n",
    "                           batch_size=4,\n",
    "                           num_steps=num_steps,\n",
    "                           snr=signal_to_noise_ratio,\n",
    "                           device=device,\n",
    "                           eps=1e-3) \n",
    "\n",
    "  xr.Dataset(data_vars={'ssh':(('time','lat','lon'),x_estim.detach().cpu()[0])},\n",
    "           coords={'time':np.arange(15),\n",
    "                   'lon':np.arange(-66, -54, 0.05),\n",
    "                   'lat':np.arange(32, 44, 0.05)}).ssh.plot(col='time',col_wrap=5)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0PdMMadpUbrj"
   },
   "source": [
    "## Sampling with Numerical ODE Solvers\n",
    "\n",
    "For any SDE of the form\n",
    "\\begin{align*}\n",
    "d \\mathbf{x} = \\mathbf{f}(\\mathbf{x}, t) d t + g(t) d \\mathbf{w},\n",
    "\\end{align*}\n",
    "there exists an associated ordinary differential equation (ODE)\n",
    "\\begin{align*}\n",
    "d \\mathbf{x} = \\bigg[\\mathbf{f}(\\mathbf{x}, t) - \\frac{1}{2}g(t)^2 \\nabla_\\mathbf{x} \\log p_t(\\mathbf{x})\\bigg] dt,\n",
    "\\end{align*}\n",
    "such that their trajectories have the same mariginal probability density $p_t(\\mathbf{x})$. Therefore, by solving this ODE in the reverse time direction, we can sample from the same distribution as solving the reverse-time SDE.\n",
    "We call this ODE the *probability flow ODE*.\n",
    "\n",
    "Below is a schematic figure showing how trajectories from this probability flow ODE differ from SDE trajectories, while still sampling from the same distribution.\n",
    "![SDE and ODE](https://drive.google.com/uc?id=1CGFbtY2mCjlIY8pjvoGevfa_32d4b1dj)\n",
    "\n",
    "Therefore, we can start from a sample from $p_T$, integrate the ODE in the reverse time direction, and then get a sample from $p_0$. In particular, for the SDE in our running example, we can integrate the following ODE from $t=T$ to $0$ for sample generation\n",
    "\\begin{align*}\n",
    "d\\mathbf{x} =  -\\frac{1}{2}\\sigma^{2t} s_\\theta(\\mathbf{x}, t) dt.\n",
    "\\end{align*}\n",
    "This can be done using many black-box ODE solvers provided by packages such as `scipy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cellView": "form",
    "id": "nxrCTFM8CfDN"
   },
   "outputs": [],
   "source": [
    "#@title Define the ODE sampler (double click to expand or collapse)\n",
    "\n",
    "from scipy import integrate\n",
    "\n",
    "## The error tolerance for the black-box ODE solver\n",
    "error_tolerance = 1e-5 #@param {'type': 'number'}\n",
    "def ode_sampler(score_model,\n",
    "                marginal_prob_std,\n",
    "                diffusion_coeff,\n",
    "                y,\n",
    "                batch_size=64,\n",
    "                atol=error_tolerance,\n",
    "                rtol=error_tolerance,\n",
    "                device='cuda',\n",
    "                z=None,\n",
    "                eps=1e-3):\n",
    "  \"\"\"Generate samples from score-based models with black-box ODE solvers.\n",
    "\n",
    "  Args:\n",
    "    score_model: A PyTorch model that represents the time-dependent score-based model.\n",
    "    marginal_prob_std: A function that returns the standard deviation\n",
    "      of the perturbation kernel.\n",
    "    diffusion_coeff: A function that returns the diffusion coefficient of the SDE.\n",
    "    batch_size: The number of samplers to generate by calling this function once.\n",
    "    atol: Tolerance of absolute errors.\n",
    "    rtol: Tolerance of relative errors.\n",
    "    device: 'cuda' for running on GPUs, and 'cpu' for running on CPUs.\n",
    "    z: The latent code that governs the final sample. If None, we start from p_1;\n",
    "      otherwise, we start from the given z.\n",
    "    eps: The smallest time step for numerical stability.\n",
    "  \"\"\"\n",
    "  t = torch.ones(batch_size, device=device)\n",
    "  # Create the latent code\n",
    "  if z is None:\n",
    "    init_x = torch.randn(batch_size, 9, 120, 120, device=device) \\\n",
    "      * marginal_prob_std(t)[:, None, None, None]\n",
    "  else:\n",
    "    init_x = z\n",
    "\n",
    "  shape = init_x.shape\n",
    "\n",
    "  def score_eval_wrapper(sample, y, time_steps):\n",
    "    \"\"\"A wrapper of the score-based model for use by the ODE solver.\"\"\"\n",
    "    sample = torch.tensor(sample, device=device, dtype=torch.float32).reshape(shape)\n",
    "    y = torch.tensor(y, device=device, dtype=torch.float32).reshape(shape)\n",
    "    time_steps = torch.tensor(time_steps, device=device, dtype=torch.float32).reshape((sample.shape[0], ))\n",
    "    with torch.no_grad():\n",
    "      score = score_model(sample, y, time_steps)\n",
    "    return score.cpu().numpy().reshape((-1,)).astype(np.float64)\n",
    "\n",
    "  def ode_func(t, x):\n",
    "    \"\"\"The ODE function for use by the ODE solver.\"\"\"\n",
    "    time_steps = np.ones((shape[0],)) * t\n",
    "    g = diffusion_coeff(torch.tensor(t)).cpu().numpy()\n",
    "    return  -0.5 * (g**2) * score_eval_wrapper(x, y, time_steps)\n",
    "\n",
    "  # Run the black-box ODE solver.\n",
    "  res = integrate.solve_ivp(ode_func, (1., eps), init_x.reshape(-1).cpu().numpy(), rtol=rtol, atol=atol, method='RK45')\n",
    "  print(f\"Number of function evaluations: {res.nfev}\")\n",
    "  x = torch.tensor(res.y[:, -1], device=device).reshape(shape)\n",
    "\n",
    "  return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding this Supervised Loss: how it works intuitively\n",
    "\n",
    "### First, some basic knowledge about Gaussian distribution\n",
    "\n",
    "\n",
    "We start by proving: $\\nabla_x \\log \\mathcal{N}(x; \\mu, \\Sigma) = -\\Sigma^{-1} (x - \\mu)$\n",
    "Indeed, the probability density function of a Gaussian (normal) distribution $ \\mathcal{N}(x; \\mu, \\Sigma) $ is given by:\n",
    "$$\n",
    "p(x) = \\frac{1}{\\sqrt{(2\\pi)^d |\\Sigma|}} \\exp\\left(-\\frac{1}{2} (x - \\mu)^T \\Sigma^{-1} (x - \\mu)\\right)\n",
    "$$\n",
    "where:\n",
    "- $\\mu$ is the mean vector, $\\Sigma$ is the covariance matrix, $d$ is the dimensionality of $x$, $|\\Sigma|$ is the determinant of the covariance matrix.\n",
    "\n",
    "Then the log of the Gaussian probability density is:\n",
    "$$\n",
    "\\log p(x) = -\\frac{d}{2} \\log(2\\pi) - \\frac{1}{2} \\log |\\Sigma| - \\frac{1}{2} (x - \\mu)^T \\Sigma^{-1} (x - \\mu)\n",
    "$$\n",
    "\n",
    "Take the gradient of the log probability with respect to $x$:\n",
    "$$\n",
    "\\nabla_x \\log p(x) = \\nabla_x \\left( -\\frac{1}{2} (x - \\mu)^T \\Sigma^{-1} (x - \\mu) \\right)\n",
    "$$\n",
    "Using matrix calculus, the gradient of the quadratic form is:\n",
    "$$\n",
    "\\nabla_x \\left( (x - \\mu)^T \\Sigma^{-1} (x - \\mu) \\right) = 2 \\Sigma^{-1} (x - \\mu)\n",
    "$$\n",
    "Thus, the score function is:\n",
    "$$\n",
    "\\nabla_x \\log p(x) = -\\Sigma^{-1} (x - \\mu)\n",
    "$$\n",
    "\n",
    "### Now, we try to understand the Loss with Transition Probability as a Gaussian\n",
    "\n",
    "In the context of the score-based generative model, the perturbation process from \\( x(0) \\) to \\( x(t) \\) is modeled as a Gaussian:\n",
    "\n",
    "$\n",
    "p_{0t}(x(t) \\mid x(0)) = \\mathcal{N}(x(t); x(0), \\text{std}^2(t) I).\n",
    "$\n",
    "\n",
    "The Gaussian form of the transition probability:\n",
    "\n",
    "$$\n",
    "p_{0t}(x(t) \\mid x(0)) = \\frac{1}{(2\\pi \\text{std}^2(t))^{d/2}} \\exp\\left(-\\frac{\\|x(t) - x(0)\\|^2}{2 \\text{std}^2(t)}\\right).\n",
    "$$\n",
    "\n",
    "Compute the gradient of the log probability with respect to $x(t)$:\n",
    "\n",
    "$$\n",
    "\\log p_{0t}(x(t) \\mid x(0)) = -\\frac{d}{2} \\log(2\\pi \\text{std}^2(t)) - \\frac{\\|x(t) - x(0)\\|^2}{2 \\text{std}^2(t)}\n",
    "$$\n",
    "\n",
    "Taking the gradient with respect to $ x(t) $:\n",
    "\n",
    "$$\n",
    "\\nabla_{x(t)} \\log p_{0t}(x(t) \\mid x(0)) = -\\nabla_{x(t)} \\left(\\frac{\\|x(t) - x(0)\\|^2}{2 \\text{std}^2(t)}\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "Thus, the score function is:\n",
    "\n",
    "$$\n",
    "\\nabla_{x(t)} \\log p_{0t}(x(t) \\mid x(0)) = -\\frac{x(t) - x(0)}{\\text{std}^2(t)}\n",
    "$$\n",
    "\n",
    "#### Substitution with Perturbation\n",
    "\n",
    "Given that $ x(t) = x(0) + z \\cdot \\text{std}(t) $, substitute into the expression:\n",
    "\n",
    "$$\n",
    "x(t) - x(0) = z \\cdot \\text{std}(t)\n",
    "$$\n",
    "\n",
    "Substitute into the score function:\n",
    "\n",
    "$$\n",
    "\\nabla_{x(t)} \\log p_{0t}(x(t) \\mid x(0)) = -\\frac{z \\cdot \\text{std}(t)}{\\text{std}^2(t)} = -\\frac{z}{\\text{std}(t)}\n",
    "$$\n",
    "\n",
    "This yields:\n",
    "\n",
    "$$\n",
    "\\nabla_{x(t)} \\log p_{0t}(x(t) \\mid x(0)) = -\\frac{z}{\\text{std}(t)}\n",
    "$$\n",
    "\n",
    "**And this explains why we have below loss function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "064d464ef6854537bb2d8628f7c5d934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m avg_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.\u001b[39m\n\u001b[1;32m     25\u001b[0m num_items \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 26\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;66;43;03m#batch = batch.nan_to_num().to(device)\u001b[39;49;00m\n\u001b[1;32m     28\u001b[0m \u001b[43m  \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# ASIP data\u001b[39;49;00m\n\u001b[1;32m     29\u001b[0m \u001b[43m  \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# OSISAF data\u001b[39;49;00m\n",
      "File \u001b[0;32m/dmidata/users/maxb/conda/envs/4dvarnet-starter/lib/python3.12/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/dmidata/users/maxb/conda/envs/4dvarnet-starter/lib/python3.12/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/dmidata/users/maxb/conda/envs/4dvarnet-starter/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/dmidata/users/maxb/4dvarnet-starter/Notebooks/Notebook_DMI/ASIP_OSISAF/../../../contrib/DMI/ASIP_OSISAF/data_simple.py:52\u001b[0m, in \u001b[0;36mXrDataset.__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, item):\n\u001b[1;32m     51\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdb\u001b[38;5;241m.\u001b[39misel(record\u001b[38;5;241m=\u001b[39mitem,sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 52\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mTrainingItem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fields\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m     item \u001b[38;5;241m=\u001b[39m item\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m item\n",
      "File \u001b[0;32m/dmidata/users/maxb/conda/envs/4dvarnet-starter/lib/python3.12/site-packages/xarray/core/dataset.py:7260\u001b[0m, in \u001b[0;36mDataset.to_array\u001b[0;34m(self, dim, name)\u001b[0m\n\u001b[1;32m   7256\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_array\u001b[39m(\n\u001b[1;32m   7257\u001b[0m     \u001b[38;5;28mself\u001b[39m, dim: Hashable \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvariable\u001b[39m\u001b[38;5;124m\"\u001b[39m, name: Hashable \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   7258\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataArray:\n\u001b[1;32m   7259\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deprecated version of to_dataarray\"\"\"\u001b[39;00m\n\u001b[0;32m-> 7260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dataarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dmidata/users/maxb/conda/envs/4dvarnet-starter/lib/python3.12/site-packages/xarray/core/dataset.py:7243\u001b[0m, in \u001b[0;36mDataset.to_dataarray\u001b[0;34m(self, dim, name)\u001b[0m\n\u001b[1;32m   7241\u001b[0m data_vars \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariables[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_vars]\n\u001b[1;32m   7242\u001b[0m broadcast_vars \u001b[38;5;241m=\u001b[39m broadcast_variables(\u001b[38;5;241m*\u001b[39mdata_vars)\n\u001b[0;32m-> 7243\u001b[0m data \u001b[38;5;241m=\u001b[39m duck_array_ops\u001b[38;5;241m.\u001b[39mstack([\u001b[43mb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m broadcast_vars], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   7245\u001b[0m dims \u001b[38;5;241m=\u001b[39m (dim,) \u001b[38;5;241m+\u001b[39m broadcast_vars[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdims\n\u001b[1;32m   7246\u001b[0m variable \u001b[38;5;241m=\u001b[39m Variable(dims, data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrs, fastpath\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/dmidata/users/maxb/conda/envs/4dvarnet-starter/lib/python3.12/site-packages/xarray/core/variable.py:451\u001b[0m, in \u001b[0;36mVariable.data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, indexing\u001b[38;5;241m.\u001b[39mExplicitlyIndexed):\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_duck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n",
      "File \u001b[0;32m/dmidata/users/maxb/conda/envs/4dvarnet-starter/lib/python3.12/site-packages/xarray/core/indexing.py:837\u001b[0m, in \u001b[0;36mMemoryCachedArray.get_duck_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_duck_array\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 837\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ensure_cached\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    838\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray\u001b[38;5;241m.\u001b[39mget_duck_array()\n",
      "File \u001b[0;32m/dmidata/users/maxb/conda/envs/4dvarnet-starter/lib/python3.12/site-packages/xarray/core/indexing.py:831\u001b[0m, in \u001b[0;36mMemoryCachedArray._ensure_cached\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_ensure_cached\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 831\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray \u001b[38;5;241m=\u001b[39m as_indexable(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_duck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/dmidata/users/maxb/conda/envs/4dvarnet-starter/lib/python3.12/site-packages/xarray/core/indexing.py:788\u001b[0m, in \u001b[0;36mCopyOnWriteArray.get_duck_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_duck_array\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 788\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_duck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dmidata/users/maxb/conda/envs/4dvarnet-starter/lib/python3.12/site-packages/xarray/core/indexing.py:651\u001b[0m, in \u001b[0;36mLazilyIndexedArray.get_duck_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    647\u001b[0m     array \u001b[38;5;241m=\u001b[39m apply_indexer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey)\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;66;03m# If the array is not an ExplicitlyIndexedNDArrayMixin,\u001b[39;00m\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;66;03m# it may wrap a BackendArray so use its __getitem__\u001b[39;00m\n\u001b[0;32m--> 651\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;66;03m# self.array[self.key] is now a numpy array when\u001b[39;00m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;66;03m# self.array is a BackendArray subclass\u001b[39;00m\n\u001b[1;32m    655\u001b[0m \u001b[38;5;66;03m# and self.key is BasicIndexer((slice(None, None, None),))\u001b[39;00m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;66;03m# so we need the explicit check for ExplicitlyIndexed\u001b[39;00m\n\u001b[1;32m    657\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(array, ExplicitlyIndexed):\n",
      "File \u001b[0;32m/dmidata/users/maxb/conda/envs/4dvarnet-starter/lib/python3.12/site-packages/xarray/backends/netCDF4_.py:100\u001b[0m, in \u001b[0;36mNetCDF4ArrayWrapper.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m--> 100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mindexing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplicit_indexing_adapter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIndexingSupport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOUTER\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dmidata/users/maxb/conda/envs/4dvarnet-starter/lib/python3.12/site-packages/xarray/core/indexing.py:1015\u001b[0m, in \u001b[0;36mexplicit_indexing_adapter\u001b[0;34m(key, shape, indexing_support, raw_indexing_method)\u001b[0m\n\u001b[1;32m    993\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Support explicit indexing by delegating to a raw indexing method.\u001b[39;00m\n\u001b[1;32m    994\u001b[0m \n\u001b[1;32m    995\u001b[0m \u001b[38;5;124;03mOuter and/or vectorized indexers are supported by indexing a second time\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1012\u001b[0m \u001b[38;5;124;03mIndexing result, in the form of a duck numpy-array.\u001b[39;00m\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1014\u001b[0m raw_key, numpy_indices \u001b[38;5;241m=\u001b[39m decompose_indexer(key, shape, indexing_support)\n\u001b[0;32m-> 1015\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mraw_indexing_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_key\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtuple\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m numpy_indices\u001b[38;5;241m.\u001b[39mtuple:\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;66;03m# index the loaded np.ndarray\u001b[39;00m\n\u001b[1;32m   1018\u001b[0m     indexable \u001b[38;5;241m=\u001b[39m NumpyIndexingAdapter(result)\n",
      "File \u001b[0;32m/dmidata/users/maxb/conda/envs/4dvarnet-starter/lib/python3.12/site-packages/xarray/backends/netCDF4_.py:113\u001b[0m, in \u001b[0;36mNetCDF4ArrayWrapper._getitem\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatastore\u001b[38;5;241m.\u001b[39mlock:\n\u001b[1;32m    112\u001b[0m         original_array \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_array(needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 113\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43mgetitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# Catch IndexError in netCDF4 and return a more informative\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# error message.  This is most often called when an unsorted\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# indexer is used before the data is loaded from disk.\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    119\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe indexing operation you are attempting to perform \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    120\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis not valid on netCDF4.Variable object. Try loading \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    121\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data into memory first by calling .load().\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    122\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#@title Training (double click to expand or collapse)\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from torch.optim import Adam\n",
    "from tqdm.autonotebook import tqdm\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "n_epochs =  1000#@param {'type':'integer'}\n",
    "## learning rate\n",
    "lr = 1e-3 #@param {'type':'number'}\n",
    "\n",
    "score_model = torch.nn.DataParallel(ScoreNet(marginal_prob_std=marginal_prob_std_fn))\n",
    "score_model = score_model.to(device)\n",
    "#ckpt = torch.load('ckpt/ckpt_diff_srnn_ASIP_forecast.pth', map_location=device)\n",
    "#score_model.load_state_dict(ckpt)\n",
    "\n",
    "optimizer = Adam(score_model.parameters(), lr=lr)\n",
    "scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[100, 200, 300, 400,450, 600,800,1000,1200,1400], gamma=0.5)\n",
    "\n",
    "tqdm_epoch = tqdm(range(n_epochs))\n",
    "for epoch in tqdm_epoch:\n",
    "  avg_loss = 0.\n",
    "  num_items = 0\n",
    "  for batch in data_loader:\n",
    "    #batch = batch.nan_to_num().to(device)\n",
    "    x = batch[:,0,:,:,:].to(device) # ASIP data\n",
    "    y = batch[:,1,:,:,:].to(device) # OSISAF data\n",
    "    #y = F.avg_pool2d(x,kernel_size=11, stride=1, padding=(5,5), count_include_pad=False) # coarsen_ASIP (*10)\n",
    "    \"\"\"\n",
    "    xr.Dataset(data_vars={'ssh':(('time','lat','lon'),x.detach().cpu()[0])},\n",
    "           coords={'time':np.arange(8),\n",
    "                   'lon':np.arange(-66, -54, 0.05),\n",
    "                   'lat':np.arange(32, 44, 0.05)}).ssh.plot(col='time',col_wrap=8,vmin=0,vmax=1)\n",
    "    plt.show()\n",
    "    xr.Dataset(data_vars={'ssh':(('time','lat','lon'),y.detach().cpu()[0])},\n",
    "           coords={'time':np.arange(8),\n",
    "                   'lon':np.arange(-66, -54, 0.05),\n",
    "                   'lat':np.arange(32, 44, 0.05)}).ssh.plot(col='time',col_wrap=8,vmin=0,vmax=1)\n",
    "    plt.show()\n",
    "    \"\"\"\n",
    "    x = torch.unsqueeze(x, 1)\n",
    "    y = torch.unsqueeze(y, 1)\n",
    "    # mask OSISAF for forecasting\n",
    "    y[:,:,5:,:,:] = np.nan\n",
    "      \n",
    "    loss = masked_loss_fn(score_model, x, y, marginal_prob_std_fn)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    avg_loss += loss.item() * x.shape[0]\n",
    "    num_items += x.shape[0]\n",
    "  # Print the averaged training loss so far.\n",
    "  tqdm_epoch.set_description('Average Loss: {:5f}'.format(avg_loss / num_items))\n",
    "  # Update the checkpoint after each epoch of training.\n",
    "  torch.save(score_model.state_dict(), 'ckpt/ckpt_diff_srnn_ASIP_forecast.pth')\n",
    "  scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_model = torch.nn.DataParallel(ScoreNet(marginal_prob_std=marginal_prob_std_fn))\n",
    "score_model = score_model.to(device)\n",
    "ckpt = torch.load('ckpt/ckpt_diff_srnn_ASIP_forecast.pth', map_location=device)\n",
    "score_model.load_state_dict(ckpt)\n",
    "\n",
    "\n",
    "k = 10\n",
    "batch = next(itertools.islice(data_loader, k, None))\n",
    "x = batch[:,0,:,:,:].to(device) # ASIP data\n",
    "y = batch[:,1,:,:,:].to(device) # OSISAF data\n",
    "x = torch.unsqueeze(x, 1)\n",
    "y = torch.unsqueeze(y, 1)\n",
    "y[:,:,5:,:,:] = np.nan\n",
    "#x = x[[0]]\n",
    "#std = marginal_prob_std(1,25)\n",
    "#z = torch.randn_like(x)\n",
    "#x = x + z * std\n",
    "#y = y[[0]]\n",
    "\n",
    "sampler = Euler_Maruyama_sampler #@param ['Euler_Maruyama_sampler', 'pc_sampler', 'ode_sampler'] {'type': 'raw'}\n",
    "x_estim = sampler(score_model,\n",
    "                  marginal_prob_std_fn,\n",
    "                  diffusion_coeff_fn,\n",
    "                  y.nan_to_num().to(device),\n",
    "                  batch_size=x.shape[0],\n",
    "                  num_steps=500,\n",
    "                  device=device)\n",
    "x_estim2 = sampler(score_model,\n",
    "                  marginal_prob_std_fn,\n",
    "                  diffusion_coeff_fn,\n",
    "                  y.nan_to_num().to(device),\n",
    "                  batch_size=x.shape[0],\n",
    "                  num_steps=500,\n",
    "                  device=device)\n",
    "\n",
    "x = x.squeeze()\n",
    "if len(x.shape)==3:\n",
    "    x = torch.unsqueeze(x, 0)\n",
    "y = y.squeeze()\n",
    "if len(y.shape)==3:\n",
    "    y = torch.unsqueeze(y, 0)\n",
    "x_estim = x_estim.squeeze()\n",
    "if len(x_estim.shape)==3:\n",
    "    x_estim = torch.unsqueeze(x_estim, 0)\n",
    "x_estim2 = x_estim2.squeeze()\n",
    "if len(x_estim2.shape)==3:\n",
    "    x_estim2 = torch.unsqueeze(x_estim2, 0)\n",
    "    \n",
    "x_estim[torch.isnan(y)] = np.nan\n",
    "xr.Dataset(data_vars={'ssh':(('time','lat','lon'),y.detach().cpu()[0])},\n",
    "           coords={'time':np.arange(8),\n",
    "                   'lon':np.arange(-66, -54, 0.05),\n",
    "                   'lat':np.arange(32, 44, 0.05)}).ssh.plot(col='time',col_wrap=9,vmin=0,vmax=1)\n",
    "plt.show()\n",
    "xr.Dataset(data_vars={'ssh':(('time','lat','lon'),x.detach().cpu()[0])},\n",
    "           coords={'time':np.arange(8),\n",
    "                   'lon':np.arange(-66, -54, 0.05),\n",
    "                   'lat':np.arange(32, 44, 0.05)}).ssh.plot(col='time',col_wrap=9,vmin=0,vmax=1)\n",
    "plt.show()\n",
    "xr.Dataset(data_vars={'ssh':(('time','lat','lon'),x_estim.detach().cpu()[0])},\n",
    "           coords={'time':np.arange(8),\n",
    "                   'lon':np.arange(-66, -54, 0.05),\n",
    "                   'lat':np.arange(32, 44, 0.05)}).ssh.plot(col='time',col_wrap=9,vmin=0,vmax=1)\n",
    "plt.show()\n",
    "xr.Dataset(data_vars={'ssh':(('time','lat','lon'),x_estim2.detach().cpu()[0])},\n",
    "           coords={'time':np.arange(8),\n",
    "                   'lon':np.arange(-66, -54, 0.05),\n",
    "                   'lat':np.arange(32, 44, 0.05)}).ssh.plot(col='time',col_wrap=9,vmin=0,vmax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1f4487629d4646459e9923bea2461cf3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.4.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.4.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.4.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4c463140b56245d98996048fd4c78b22",
      "placeholder": "",
      "style": "IPY_MODEL_42bd42a903de4d3f8c7f741fc99695d5",
      "value": "Average bits/dim: 4.111211:   1%"
     }
    },
    "32c4f6132fca4c6797b317db5bd35938": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.1.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.1.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.1.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "42bd42a903de4d3f8c7f741fc99695d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.4.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.4.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.1.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "488efe83bb0c4675a8f7f6c88b2796d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.1.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.1.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.1.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4c463140b56245d98996048fd4c78b22": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.1.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.1.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.1.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "61a88f148b8e48adb16bccd7db3eeaf8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.4.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.4.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.1.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "64b0fddd0f2544468c028b6da780515c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.4.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.4.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.1.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6702c584e95347ae8d425257b8ec540e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.4.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.4.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.4.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_81a3a9c9a6b742fa9f8f19f71fedd73a",
      "placeholder": "",
      "style": "IPY_MODEL_64b0fddd0f2544468c028b6da780515c",
      "value": " 50/50 [20:59&lt;00:00, 25.18s/it]"
     }
    },
    "6f6b56e6662149caad3e30815c25e374": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.4.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.4.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.4.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6fd034cfc2b74649ae887af76e13cbe5",
      "max": 50,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c4de8fe7e05142a78560e13c2b1ca385",
      "value": 50
     }
    },
    "6fd034cfc2b74649ae887af76e13cbe5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.1.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.1.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.1.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7d060cf0423f48d09b5ad434e8254ec2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.4.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.4.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.1.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "81a3a9c9a6b742fa9f8f19f71fedd73a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.1.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.1.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.1.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9fe9af58fc544fce975120a09e8cc329": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.4.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.4.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.1.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b1308d495dd643b48378ff372c8f9c3a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.4.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.4.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.4.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c14794e9abf641a9884a0dd618e14d1e",
       "IPY_MODEL_6f6b56e6662149caad3e30815c25e374",
       "IPY_MODEL_6702c584e95347ae8d425257b8ec540e"
      ],
      "layout": "IPY_MODEL_cdf00304d2da46a1bfc2e86542882db4"
     }
    },
    "b41078ed64a24f68a69f821fc32791ad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.1.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.1.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.1.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c14794e9abf641a9884a0dd618e14d1e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.4.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.4.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.4.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d909e838a6894af4abe248ea52bbeb93",
      "placeholder": "",
      "style": "IPY_MODEL_61a88f148b8e48adb16bccd7db3eeaf8",
      "value": "Average Loss: 17.045697: 100%"
     }
    },
    "c4de8fe7e05142a78560e13c2b1ca385": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.4.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.4.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.1.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cdf00304d2da46a1bfc2e86542882db4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.1.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.1.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.1.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d1b99c321d8b4256bc9c4267fbafa224": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.4.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.4.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.4.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_32c4f6132fca4c6797b317db5bd35938",
      "max": 313,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9fe9af58fc544fce975120a09e8cc329",
      "value": 2
     }
    },
    "d909e838a6894af4abe248ea52bbeb93": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.1.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.1.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.1.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "db075f0871564f5da3119833dcffbf17": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.4.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.4.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.4.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1f4487629d4646459e9923bea2461cf3",
       "IPY_MODEL_d1b99c321d8b4256bc9c4267fbafa224",
       "IPY_MODEL_dded254d850e4f86a778aa73439ebc48"
      ],
      "layout": "IPY_MODEL_488efe83bb0c4675a8f7f6c88b2796d6"
     }
    },
    "dded254d850e4f86a778aa73439ebc48": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.4.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.4.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.4.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b41078ed64a24f68a69f821fc32791ad",
      "placeholder": "",
      "style": "IPY_MODEL_7d060cf0423f48d09b5ad434e8254ec2",
      "value": " 2/313 [00:19&lt;50:11,  9.68s/it]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
